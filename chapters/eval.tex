\chapter{\ifproject%
\ifenglish Experimentation and Results\else การทดลองและผลลัพธ์\fi
\else%
\ifenglish System Evaluation\else การประเมินระบบ\fi
\fi}

In this section, we delve into the experimentation phase of our project, where 
the proposed methodologies were put to the test, and their efficacy was evaluated. 
The primary objective was to assess the performance and suitability of the 
recommendation system in providing personalized course recommendations to users.

\section{Data Preparation}

\subsection{Import Datasets}
The dataset provided by the developer is required to be a csv format and consists of two main components:
\begin{minted}[frame=lines, fontsize=\footnotesize]{python}
import pandas as pd
i_data = pd.read_csv('https://startg2545.github.io/item_tutorial.csv')
ui_data = pd.read_csv('https://startg2545.github.io/user_item_tutorial.csv')
\end{minted}

\subsection{Import the Classes}

First of all, import one of these classes from the isne\_recommendation 
module that you desire to evaluate the model.

\begin{minted}[frame=lines, fontsize=\footnotesize]{python}
from isne_recommendation import TfidfLinearKernel, FeatureRatingsKNN, Hybrid
\end{minted}

\subsection{Fit the Model}

The fit function is responsible for adjusting the internal parameters of the model 
to minimize the difference between the predicted outputs and the actual outputs 
(also known as the ground truth) in the training data.

\begin{minted}[frame=lines, fontsize=\footnotesize]{python}
model = TfidfLinearKernel.fit(i_data)
model = FeatureRatingsKNN.fit(ui_data)
model = Hybrid.fit(i_data, ui_data)
\end{minted}

\newpage
\section{Split the Data for training and testing}

The \textit{train-test split} is a common technique used in machine learning to evaluate the 
performance of a model on unseen data. This technique involves splitting the dataset 
into two subsets: one for training the model and another for testing its performance

\begin{minted}[frame=lines, fontsize=\footnotesize]{python}
train, test = TfidfLinearKernel.train_test_split(ui_data)
\end{minted}

\section{Evaluate the model}

Model evaluation is a crucial step in machine learning to assess the performance and 
effectiveness of a trained model on unseen data. The model evaluation function involves 
using various metrics and techniques to measure how well the model generalizes to new data.

\begin{minted}[frame=lines, fontsize=\footnotesize]{python}
# Calculate the hit rate of the model
hit_rate = TfidfLinearKernel.hit_rate(train, test, i_data, model)
hit_rate = FeatureRatingsKNN.hit_rate(train, test, model)
hit_rate = Hybrid.hit_rate(train, test, i_data, model)
# Calculate the F1 score of the model
f1_score = TfidfLinearKernel.f1_score(train, test, i_data, model)
f1_score = FeatureRatingsKNN.f1_score(train, test, model)
f1_score = Hybrid.f1_score(train, test, i_data, model)
\end{minted}

\section{Performance Evaluation}

\begin{enumerate}
    \item \textbf{First Approach}:
    \begin{itemize}
        \item Hit Rate Accuracy: 14.69\%
        \item F1 Score Accuracy: 2.58\%
    \end{itemize}
    \item \textbf{Second Approach}:
    \begin{itemize}
        \item Hit Rate Accuracy: 48.24\%
        \item F1 Score Accuracy: 7.92\%
    \end{itemize}
    \item \textbf{Hybrid Approach}:
    \begin{itemize}
        \item Hit Rate Accuracy: 69.18\%
        \item F1 Score Accuracy: 11.62\%
    \end{itemize}
\end{enumerate}