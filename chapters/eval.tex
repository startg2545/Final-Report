\chapter{\ifproject%
\ifenglish Experimentation and Results\else การทดลองและผลลัพธ์\fi
\else%
\ifenglish System Evaluation\else การประเมินระบบ\fi
\fi}

In this section, we delve into the experimentation phase of our project, where 
the proposed methodologies were put to the test, and their efficiency was 
evaluated. The primary objective is to assess the performance of the 
recommendation system in providing personalized course recommendations to users.

\section{Install our Python package}

To install the isne-recommendation Python package, you can use the pip command 
in your terminal or command prompt.

\begin{minted}[frame=lines, fontsize=\footnotesize, escapeinside=||]{powershell}
|\textcolor{olive}{pip} install isne-recommendation|
\end{minted}

\noindent If you're using a Jupyter notebook, you can run this command in a 
Jupyter Notebook by prefixing it with an exclamation mark:

\begin{minted}[frame=lines, fontsize=\footnotesize, escapeinside=||]{powershell}
|\textcolor{blue}{!}pip install isne-recommendation|
\end{minted}

\section{Data Preparation}

In this section, we are going to write Python in the Jupyter Notebook 
and import classes from the isne\_recommendation module 
that we will use to assess the model's performance and import the datasets 
necessary for our evaluation.

\subsection{Import the classes}

Import one or more classes from the isne\_recommendation module that originally 
were hosted on Python Package Index (PyPI) and now are available on GitHub. 

\begin{minted}[frame=lines, fontsize=\footnotesize]{python}
from isne_recommendation import TfidfLinearKernel, FeatureRatingsKNN, Hybrid
\end{minted}

\subsection{Import datasets}

The dataset provided by the developer is needed to be a csv format and consists of two main components:

\begin{minted}[frame=lines, fontsize=\footnotesize]{python}
import pandas as pd
item_df = pd.read_csv('https://startg2545.github.io/item_tutorial.csv')
user_df = pd.read_csv('https://startg2545.github.io/user_item_tutorial.csv')
\end{minted}

\section{Extract a user dataset}

It is crucial to split the dataset into training and testing sets to erase the 
test data from model's memories.

\begin{minted}[frame=lines, fontsize=\footnotesize]{python}
train, test = TfidfLinearKernel.train_test_split(user_df, test_size=0.25)
\end{minted}

\section{Fit the model}

The next step is to train the model using the training dataset.

\begin{minted}[frame=lines, fontsize=\footnotesize]{python}
tfidf_matrix = TfidfLinearKernel.fit(item_df)
knn_model = FeatureRatingsKNN.fit(train)
hybrid_knn_model = Hybrid.fit(item_df, train)
\end{minted}

\section{Predict the model}

So far, you can predict recommendations for every user, analyze and 
incorporate them into the performance assessment. 
Let's take an example of a user named \textit{Tracy Marchant} below:

\begin{minted}[frame=lines, fontsize=\footnotesize]{python}
# This compares the model's predictions against the actual preferences in the test set.
true = test[test['username'] == 'Tracy Marchant']['course'] # actual preferences
first_prediction = TfidfLinearKernel.predict('Tracy Marchant', item_df, train, tfidf_matrix, 10)
second_prediction = FeatureRatingsKNN.predict('Tracy Marchant', train, knn_model, 10)
hybrid_prediction = Hybrid.predict('Tracy Marchant', item_df, train, hybrid_knn_model, 10)
\end{minted}

\section{Observe the results}

This user has taken totally six courses, and the \textit{test\_size} is 25\%, 
so the test set contains two courses by rounding.

\begin{minted}[frame=lines, fontsize=\footnotesize]{python}
true
\end{minted}

\begin{table}[H]
\small
\begin{tabular}{|p{0.5cm}|p{10cm}|}
\hline
& Course \\
\hline
647 & Introduction to English Common Law \\
645 & Retrieve Data using Single-Table SQL Queries \\
\hline
\end{tabular}
\end{table}

\newpage
\noindent The first approach recommends the following courses:

\begin{minted}[frame=lines, fontsize=\footnotesize]{python}
first_prediction
\end{minted}

\begin{table}[H]
\small
\begin{tabular}{|p{0.5cm}|p{10cm}|p{1.5cm}|}
\hline
& Course & Score \\
\hline
79 & Write A Feature Length Screenplay For Film Or Television & 0.2627 \\
8 & COVID-19 - A clinical update & 0.2559 \\
43 & Introduction to International Criminal Law & 0.2535 \\
40 & Health Care IT: Challenges and Opportunities & 0.2400 \\
3 & Biomedical Visualisation & 0.2353 \\
67 & Sharpened Visions: A Poetry Workshop & 0.2334 \\
22 & EU policy and implementation: making Europe work! & 0.2303 \\
62 & Python and Machine Learning for Asset Management & 0.2301 \\
17 & Design and Analyze Secure Networked Systems & 0.2262 \\
68 & Social Media Management & 0.2217 \\
\hline
\end{tabular}
\end{table}

\noindent The second approach recommends the following courses:

\begin{minted}[frame=lines, fontsize=\footnotesize]{python}
second_prediction
\end{minted}

\begin{table}[H]
\small
\begin{tabular}{|p{0.5cm}|p{10cm}|p{1.5cm}|p{1.5cm}|}
\hline
& Course & Cosine Distance & Score \\
\hline
0 & The Product Lifecycle: A Guide from start to finish & 0.7808 & 0.2191 \\
2 & Retrieve Data using Single-Table SQL Queries & 0.6214 & 0.3785 \\
\hline
\end{tabular}
\end{table}

\noindent The hybrid approach recommends the following courses:

\begin{minted}[frame=lines, fontsize=\footnotesize]{python}
hybrid_prediction
\end{minted}

\begin{table}[H]
\small
\begin{tabular}{|p{0.5cm}|p{10cm}|p{1.5cm}|}
\hline
& Course & Score \\
\hline
43 & Retrieve Data using Single-Table SQL Queries & 0.5920 \\
46 & The Product Lifecycle: A Guide from start to finish & 0.2088 \\
15 & Digitalisation in Space Research & 0.1745 \\
9 & Collaborate on Files in Slack: Local \& Google Drive Integrations & 0.1670 \\
41 & Python and Machine Learning for Asset Management & 0.1134 \\
18 & EU policy and implementation: making Europe work! & 0.0855 \\
1 & Addiction Treatment: Clinical Skills for Healthcare Providers & 0.0794 \\
48 & Water Supply and Sanitation Policy in Developing Countries Part 1: Understanding Complex Problems & 0.0769 \\
8 & Coaching Practices & 0.0764 \\
25 & Fundamental Neuroscience for Neuroimaging & 0.0711 \\
\hline
\end{tabular}
\end{table}

\section{Calculate the accuracy}

\subsection{Tracy Marchant}

There is no certain function to calculate the hit rate and F1 score for a
single user. However, you can calculate them manually. Here are the results for 
\textit{Tracy Marchant}:

\subsubsection{Hit Rate}

\begin{itemize}
    \item \textbf{First Approach}: \textit{Miss}, a predicted course does not appear in the actual preferences
    \item \textbf{Second Approach}: \textit{Hit}, a predicted course appears in the actual preferences
    \item \textbf{Hybrid Approach}: \textit{Hit}, a predicted course appears in the actual preferences
\end{itemize}

\subsubsection{F1 Score}

\begin{itemize}
    \item \textbf{First Approach}: \textit{Precision} = 0.0, \textit{Recall} = 0.0, \textit{F1 Score} = 0.0
    \item \textbf{Second Approach}: \textit{Precision} = 0.5, \textit{Recall} = 0.5, \textit{F1 Score} = 0.5
    \item \textbf{Hybrid Approach}: \textit{Precision} = 0.1, \textit{Recall} = 0.5, \textit{F1 Score} = 0.1667
\end{itemize}

\subsection{All users}

For the model evaluation, you are capable to calculate the hit rate and F1 score 
for all approaches by following the code below:

\begin{minted}[frame=lines, fontsize=\footnotesize]{python}
# first model evaluation
first_hit_rate = TfidfLinearKernel.hit_rate(train, test, item_df, tfidf_matrix)
first_f1_score = TfidfLinearKernel.f1_score(train, test, item_df, tfidf_matrix)

# second model evaluation
second_hit_rate = FeatureRatingsKNN.hit_rate(train, test, knn_model)
second_f1_score = FeatureRatingsKNN.f1_score(train, test, knn_model)

# hybrid model evaluation
hybrid_hit_rate = Hybrid.hit_rate(train, test, item_df, hybrid_knn_model)
hybrid_f1_score = Hybrid.f1_score(train, test, item_df, hybrid_knn_model)
\end{minted}

\subsubsection{Hit Rate}

\begin{itemize}
    \item \textbf{First Approach}: \textit{Hit Rate Accuracy} = 14.69\%
    \item \textbf{Second Approach}: \textit{Hit Rate Accuracy} = 48.24\%
    \item \textbf{Hybrid Approach}: \textit{Hit Rate Accuracy} = 69.18\%
\end{itemize}

\subsubsection{F1 Score}

\begin{itemize}
    \item \textbf{First Approach}: \textit{F1 Score Accuracy} = 2.58\%
    \item \textbf{Second Approach}: \textit{F1 Score Accuracy} = 7.92\%
    \item \textbf{Hybrid Approach}: \textit{F1 Score Accuracy} = 11.62\%
\end{itemize}